# DON'T FORGET TO RENAME TO .env OR .env.local BEFORE PUSHING TO GIT

### DEVELOPMENT ONLY VARIABLES #########################################################################################
# These variables need to be set for local development only

# Mandatory next-auth URL for localhost
NEXTAUTH_URL=http://localhost:3000

# Set this to 1 or true to enable localhost access.
# Don't set this variable when deployed to production.
NEXT_PUBLIC_ENABLE_LOCALHOST=1

### DOCKER COMPOSE VARIABLES ###########################################################################################
# These variables need to be set if you are using Docker Compose

POSTGRES_PASSWORD=replace_with_random_string
SRH_TOKEN=replace_with_random_string

### PRODUCTION & DEVELOPMENT VARIABLES #################################################################################
# These variables need to be set for local development and when deployed

# Change this to your own domain
NEXT_PUBLIC_ROOT_DOMAIN=example.com

# PostgreSQL database
# The PostgreSQL database is used to store users, AI configurations, knowledge, and more.
# POSTGRES_PRISMA_URL uses connection pooling.
# POSTGRES_URL_NON_POOLING uses a direct connection.
#
# Setup instructions:
# - All providers: https://www.prisma.io/docs/orm/overview/databases/postgresql
# - Vercel: https://vercel.com/docs/storage/vercel-postgres/quickstart
POSTGRES_PRISMA_URL="postgresql://ownai:${POSTGRES_PASSWORD}@postgres:5432/ownai?schema=public"
POSTGRES_URL_NON_POOLING="postgresql://ownai:${POSTGRES_PASSWORD}@postgres:5432/ownai?schema=public"

# Blob Storage for image uploads
# Currently, image upload is only implemented for Vercel Blob Storage.
# If you don't use Vercel, you can leave this blank and image upload will be disabled.
#
# Setup instructions:
# – Vercel: https://vercel.com/docs/storage/vercel-blob/quickstart
BLOB_READ_WRITE_TOKEN=

# Redis / KV database
# Redis is used to save chat histories and for rate limiting.
# To access Redis, KV uses HTTP instead of the Redis binary protocol.
# This is compatible with Upstash Redis as well as Serverless Redis HTTP (SRH):
# https://github.com/hiett/serverless-redis-http
#
# KV_URL is the URL to your Redis server instance, starting with redis://
# KV_REST_API_URL is the URL to your KV or Upstash Redis or Serverless Redis HTTP instance, starting with https://
# KV_REST_API_TOKEN and KV_REST_API_READ_ONLY_TOKEN are the tokens to access KV/Upstash/SRH.
#
# Setup instructions:
# - SRH with Docker: https://github.com/vercel/storage/issues/281#issuecomment-2067729077
# – Vercel: https://vercel.com/docs/storage/vercel-kv/quickstart
KV_URL=redis://redis:6379
KV_REST_API_URL=http://kv:80
KV_REST_API_TOKEN=${SRH_TOKEN}
KV_REST_API_READ_ONLY_TOKEN=

# Random secret for authentication
# To generate, run: openssl rand -hex 16
# Or generate online: https://generate-secret.vercel.app/32
NEXTAUTH_SECRET=replace_with_random_string

# Settings for sending authentication emails
EMAIL_SERVER_USER=
EMAIL_SERVER_PASSWORD=
EMAIL_SERVER_HOST=
EMAIL_SERVER_PORT=
EMAIL_FROM=

# Settings for configuring custom domains with Vercel
# These settings allow users to add custom domains to your Vercel project.
# If you don't use Vercel, you don't need them.
#
# AUTH_BEARER_TOKEN can be found here: https://vercel.com/account/tokens
# PROJECT_ID_VERCEL can be found here: https://vercel.com/<org>/<project>/settings
# TEAM_ID_VERCEL can be found here: https://vercel.com/teams/<org>/settings
# (TEAM_ID_VERCEL is only required if you're using this with a Vercel team.)
AUTH_BEARER_TOKEN=
PROJECT_ID_VERCEL=
TEAM_ID_VERCEL=

# API for connecting to a local or remote AI model
AI_API_URL=http://ollama:11434/api
AI_API_KEY=
# AI API dialect, can be one of: openai (includes compatible providers), mistral, google, anthropic, ollama
AI_API_TYPE=ollama

# Models available for selection in AI settings, for example:
# AI_MODELS="[{ "key": "mistralai/Mixtral-8x7B-Instruct-v0.1", "label": "Mixtral v0.1 Instruct (8x7B)" }, { "key": "meta-llama/Llama-3-70b-chat-hf", "label": "Meta Llama 3 Instruct (70B)" }]"
AI_MODELS=[{"key": "phi3:mini", "label": "Phi-3 Mini"}]

# Embeddings API for generating vector embeddings from knowledge documents
# Can be the same values as AI_API if the provider supports generating embeddings.
EMBEDDINGS_API_URL=http://ollama:11434/api
EMBEDDINGS_API_KEY=
EMBEDDINGS_API_MODEL=nomic-embed-text
# Embeddings API dialect, can be one of: openai (includes compatible providers), mistral, ollama
EMBEDDINGS_API_TYPE=ollama

# Stripe (only required if you enable paid subscriptions)
STRIPE_API_KEY=
STRIPE_WEBHOOK_SECRET=
STRIPE_PRO_MONTHLY_PLAN_ID=

# External links in navigation, for example:
# NEXT_PUBLIC_EXTERNAL_LINKS="[{ "label": "Request Features", "href": "https://ownai.canny.io/feature-requests" }, { "label": "Get Support", "href": "mailto:support@ownai.com" }]"
# Can be left blank.
NEXT_PUBLIC_EXTERNAL_LINKS=

# Set this to an email address where your users can reach support.
NEXT_PUBLIC_SUPPORT_EMAIL_ADDRESS=

# Set this to 1 or true to enable subdomain mode.
# In subdomain mode, AIs get subdomain URLs, e.g. demo.ownai.com.
# This will probably require additional configuration on your name server and wildcard TLS certificates.
# In default mode the URL will be a path of the root domain, e.g. ownai.com/ai/demo
NEXT_PUBLIC_ENABLE_SUBDOMAINS=

# Set this to 1 or true to enable paid subscriptions.
NEXT_PUBLIC_ENABLE_SUBSCRIPTIONS=

# Set this to 1 or true to enable reporting with Vercel Analytics.
NEXT_PUBLIC_ENABLE_VERCEL_ANALYTICS=

# Set this to 1 or true to enable reporting Vercel Speed Insights.
NEXT_PUBLIC_ENABLE_VERCEL_SPEED_INSIGHTS=
